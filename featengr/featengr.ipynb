{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Homework \n",
    "***\n",
    "**Name**: $<$Akriti Kapur$>$ \n",
    "\n",
    "**Kaggle Username**: $<$akritikapur$>$\n",
    "***\n",
    "\n",
    "This assignment is due on Moodle by **5pm on Friday February 23rd**. Additionally, you must make at least one submission to the **Kaggle** competition before it closes at **4:59pm on Friday February 23rd**. Submit only this Jupyter notebook to Moodle. Do not compress it using tar, rar, zip, etc. Your solutions to analysis questions should be done in Markdown directly below the associated question.  Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**.  For a refresher on the course **Collaboration Policy** click [here](https://github.com/chrisketelsen/CSCI5622-Machine-Learning/blob/master/resources/syllabus.md#collaboration-policy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview \n",
    "***\n",
    "\n",
    "When people are discussing popular media, there’s a concept of spoilers. That is, critical information about the plot of a TV show, book, or movie that “ruins” the experience for people who haven’t read / seen it yet.\n",
    "\n",
    "The goal of this assignment is to do text classification on forum posts from the website [tvtropes.org](http://tvtropes.org/), to predict whether a post is a spoiler or not. We'll be using the logistic regression classifier provided by sklearn.\n",
    "\n",
    "Unlike previous assignments, the code provided with this assignment has all of the functionality required. Your job is to make the functionality better by improving the features the code uses for text classification.\n",
    "\n",
    "**NOTE**: Because the goal of this assignment is feature engineering, not classification algorithms, you may not change the underlying algorithm or it's parameters\n",
    "\n",
    "This assignment is structured in a way that approximates how classification works in the real world: Features are typically underspecified (or not specified at all). You, the data digger, have to articulate the features you need. You then compete against others to provide useful predictions.\n",
    "\n",
    "It may seem straightforward, but do not start this at the last minute. There are often many things that go wrong in testing out features, and you'll want to make sure your features work well once you've found them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle In-Class Competition \n",
    "***\n",
    "\n",
    "In addition to turning in this notebook on Moodle, you'll also need to submit your predictions on Kaggle, an online tournament site for machine learning competitions. The competition page can be found here:  \n",
    "\n",
    "[https://www.kaggle.com/c/feature-engineering-csci-5622-spring-2018](https://www.kaggle.com/c/feature-engineering-csci-5622-spring-2018)\n",
    "\n",
    "Additionally, a private invite link for the competition has been posted to Piazza. \n",
    "\n",
    "The starter code below has a `model_predict` method which produces a two column CSV file that is correctly formatted for Kaggle (predictions.csv). It should have the example Id as the first column and the prediction (`True` or `False`) as the second column. If you change this format your submissions will be scored as zero accuracy on Kaggle. \n",
    "\n",
    "**Note**: You may only submit **THREE** predictions to Kaggle per day.  Instead of using the public leaderboard as your sole evaluation processes, it is highly recommended that you perform local evaluation using a validation set or cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [25 points] Problem 1: Feature Engineering \n",
    "***\n",
    "\n",
    "The `FeatEngr` class is where the magic happens.  In it's current form it will read in the training data and vectorize it using simple Bag-of-Words.  It then trains a model and makes predictions.  \n",
    "\n",
    "25 points of your grade will be generated from your performance on the the classification competition on Kaggle. The performance will be evaluated on accuracy on the held-out test set. Half of the test set is used to evaluate accuracy on the public leaderboard.  The other half of the test set is used to evaluate accuracy on the private leaderboard (which you will not be able to see until the close of the competition). \n",
    "\n",
    "You should be able to significantly improve on the baseline system (i.e. the predictions made by the starter code we've provided) as reported by the Kaggle system.  Additionally, the top **THREE** students from the **PRIVATE** leaderboard at the end of the contest will receive 5 extra credit points towards their Problem 1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, auc, confusion_matrix, make_scorer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ne_chunk, pos_tag\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "\n",
    "def lemmatize(sentence):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "    lemmer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmer.lemmatize(word) for word in word_tokenize(sentence)])\n",
    "\n",
    "\n",
    "def stemmer(sentence):\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    return ' '.join([stemmer.stem(word) for word in sentence.split(' ')])\n",
    "\n",
    "\n",
    "def extract_emotion_features():\n",
    "    feat = ['anger', 'anxiety', 'negative_affect', 'positive_affect', 'sadness', 'swear']\n",
    "    features = {}\n",
    "    for i in feat:\n",
    "        with open(\"../data/LIWC/{}\".format(i), 'r+') as f:\n",
    "            data = f.readlines()\n",
    "            features[i] = [line.strip()[:-1] if line.strip()[-1] == '*' else line.strip() for line in data]\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def count_named_entities(examples):\n",
    "    X = np.zeros((len(examples), 1))\n",
    "\n",
    "    # Loop over examples and count words\n",
    "    for ii, x in enumerate(examples):\n",
    "        ne_tree = ne_chunk(pos_tag(word_tokenize(x)))\n",
    "        iob_tagged = tree2conlltags(ne_tree)\n",
    "        iob = [iob[2] for iob in iob_tagged]\n",
    "        X[ii, 0] = iob.count('B-PERSON') + iob.count('B-ORGANIZATION')\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def count_tense(examples):\n",
    "    tense = [['VBN', 'VBD'], ['VBG', 'VBP', 'VBZ']]\n",
    "    X = np.zeros((len(examples), 3))\n",
    "\n",
    "    # Loop over examples and count words\n",
    "    for ii, x in enumerate(examples):\n",
    "        pos_tagged = pos_tag(word_tokenize(x))\n",
    "        pos_tagged = [tag[1] for tag in pos_tagged]\n",
    "        past = sum(pos_tagged.count(i) for i in tense[0])\n",
    "        present = sum(pos_tagged.count(i) for i in tense[1])\n",
    "        other = pos_tagged.count('VB')\n",
    "\n",
    "        X[ii, :] = [past, present, other]\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def get_metrics():\n",
    "    dfTrain = pd.read_csv(\"../data/spoilers/train.csv\")\n",
    "    dfTrain_y = np.array(dfTrain[\"spoiler\"], dtype=int)\n",
    "    dfTest = pd.read_csv(\"../data/spoilers/test.csv\")\n",
    "\n",
    "    spoiler_train = dfTrain[dfTrain[\"spoiler\"] == 1]\n",
    "    non_spoiler_train = dfTrain[dfTrain[\"spoiler\"] == 0]\n",
    "\n",
    "    print(count_named_entities(spoiler_train[\"sentence\"]).mean())\n",
    "    print(count_named_entities(non_spoiler_train[\"sentence\"]).mean())\n",
    "\n",
    "    print(count_tense(spoiler_train[\"sentence\"]).mean(axis=0))\n",
    "    print(count_tense(non_spoiler_train[\"sentence\"]).mean(axis=0))\n",
    "\n",
    "\n",
    "def cross_validate(features):\n",
    "    dfTrain = pd.read_csv(\"../data/spoilers/train.csv\")\n",
    "    dfTrain_y = np.array(dfTrain[\"spoiler\"], dtype=int)\n",
    "    dfTest = pd.read_csv(\"../data/spoilers/test.csv\")\n",
    "\n",
    "    bag_of_words_vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 9), stop_words='english',\n",
    "                                              max_features=600)\n",
    "    word_vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', max_features=600)\n",
    "    vectorizer = FeatureUnion([\n",
    "        (\"bag-of-words\", word_vectorizer),\n",
    "        (\"character-ngram\", bag_of_words_vectorizer),\n",
    "    ])\n",
    "\n",
    "    trope_vector = FeatureUnion([\n",
    "        (\"character-ngrams\", TfidfVectorizer(analyzer='char_wb', ngram_range=(5, 10), max_features=600)),\n",
    "        (\"bag-of-words\", TfidfVectorizer(max_features=600))\n",
    "    ])\n",
    "\n",
    "    vectorizer_unioned = FeatureUnion(\n",
    "        transformer_list=[\n",
    "            # Pipeline for pulling features from the post's subject line\n",
    "            ('sentence', Pipeline([\n",
    "                ('selector', ItemSelector(key='sentence')),\n",
    "                ('vectorizer', vectorizer),\n",
    "            ])),\n",
    "            # Pipeline for taking length of sentence\n",
    "            ('EmotionCounts', Pipeline([\n",
    "                ('selector', ItemSelector(key='sentence')),\n",
    "                ('transformer', EmotionTransformer(None)),\n",
    "            ])),\n",
    "            # Pipeline for counting occurences of top feature words of sentence\n",
    "            ('wordCounts', Pipeline([\n",
    "                ('selector', ItemSelector(key='sentence')),\n",
    "                ('transformer', WordTransformer(lemmatize, stemmer, csr_matrix)),\n",
    "            ])),\n",
    "            # Pipeline for counting tense for sentence\n",
    "            ('NER', Pipeline([\n",
    "                ('selector', ItemSelector(key='sentence')),\n",
    "                ('transformer', NERTransformer()),\n",
    "            ])),\n",
    "            # Pipeline for counting tense for sentence\n",
    "            ('TenseVerbCounts', Pipeline([\n",
    "                ('selector', ItemSelector(key='sentence')),\n",
    "                ('transformer', TenseTransformer()),\n",
    "            ])),\n",
    "            # Pipeline for standard bag-of-words model for trope\n",
    "            ('trope', Pipeline([\n",
    "                ('selector', ItemSelector(key='trope')),\n",
    "                ('tfidf', trope_vector),\n",
    "            ])),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('tfid', vectorizer_unioned),\n",
    "        ('chi2', SelectKBest(chi2, 1000)),\n",
    "        ('classifier', LogisticRegression(random_state=1234))\n",
    "    ])\n",
    "\n",
    "    # N_FEATURES_OPTIONS = ['all']\n",
    "    # param_grid = [\n",
    "    #     {\n",
    "    #         'chi2__k': N_FEATURES_OPTIONS,\n",
    "    #     },\n",
    "    # ]\n",
    "\n",
    "    # load data\n",
    "\n",
    "    kfold = KFold(n_splits=6, random_state=1234, shuffle=False)\n",
    "    results = cross_val_score(pipe, dfTrain, dfTrain_y, cv=kfold)\n",
    "    print(results)\n",
    "\n",
    "    pipe.fit(dfTrain, dfTrain_y)\n",
    "    pred = pipe.predict(dfTest)\n",
    "    # grid = GridSearchCV(pipe, cv=kfold, n_jobs=1, param_grid=param_grid)\n",
    "    # grid.fit(list(dfTrain), list(dfTrain_y))\n",
    "    # print(np.array(grid.cv_results_['mean_test_score']))\n",
    "\n",
    "    pd.DataFrame({\"spoiler\": np.array(pred, dtype=bool)}).to_csv(\"prediction.csv\", index=True, index_label=\"Id\")\n",
    "\n",
    "\n",
    "class WordTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lemmatizer, stemmer, csr_matrix):\n",
    "        self.lemmatizer = lemmatizer\n",
    "        self.stemmer = stemmer\n",
    "        self.csr_matrix = csr_matrix\n",
    "\n",
    "    def fit(self, examples, y=None):\n",
    "        # return self and nothing else\n",
    "        return self\n",
    "\n",
    "    def transform(self, examples, y=None):\n",
    "        import numpy as np\n",
    "\n",
    "        words = ['kill', 'die', 'end', '``', 'death', 'finale', 'turn', 'reveal', 'murder', 'episode']\n",
    "\n",
    "        X = np.zeros((len(examples), len(words)))\n",
    "\n",
    "        norm_constant = 0\n",
    "        # Loop over examples and count words\n",
    "        for ii, x in enumerate(examples):\n",
    "            X[ii, :] = np.array([self.lemmatizer(self.stemmer(x)).count(word) for word in words])\n",
    "            norm_constant += np.sum(X[ii, :])\n",
    "\n",
    "        X = X / norm_constant\n",
    "        return self.csr_matrix(X)\n",
    "\n",
    "\n",
    "class NERTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, examples, y=None):\n",
    "        # return self and nothing else\n",
    "        return self\n",
    "\n",
    "    def transform(self, examples, y=None):\n",
    "        import numpy as np\n",
    "        from scipy.sparse import csr_matrix\n",
    "        X = count_named_entities(examples)\n",
    "        # X = X / norm_constant\n",
    "        return csr_matrix(X)\n",
    "\n",
    "\n",
    "class LengthTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, examples, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, examples, y=None):\n",
    "        X = np.zeros((len(examples), 1))\n",
    "        for ii, x in enumerate(examples):\n",
    "            X[ii, 0] = len(x)\n",
    "\n",
    "        return csr_matrix(X)\n",
    "\n",
    "\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "\n",
    "\n",
    "class TenseTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, examples, y=None):\n",
    "        # return self and nothing else\n",
    "        return self\n",
    "\n",
    "    def transform(self, examples, y=None):\n",
    "        import numpy as np\n",
    "        from scipy.sparse import csr_matrix\n",
    "\n",
    "        X = count_tense(examples)\n",
    "        # X = X / norm\n",
    "\n",
    "        return csr_matrix(X)\n",
    "\n",
    "\n",
    "class EmotionTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, emotiondict):\n",
    "        self.emotion_dict = emotiondict\n",
    "\n",
    "    def fit(self, examples, y=None):\n",
    "        # return self and nothing else\n",
    "        return self\n",
    "\n",
    "    def transform(self, examples, y=None):\n",
    "        import numpy as np\n",
    "        from scipy.sparse import csr_matrix\n",
    "\n",
    "        emotions = extract_emotion_features()\n",
    "        X = np.zeros((len(examples), len(emotions)))\n",
    "\n",
    "\n",
    "        norm = 1\n",
    "        # Loop over examples and count words\n",
    "        for ii, x in enumerate(examples):\n",
    "\n",
    "            X[ii, :] = [sum([x.count(word) for word in emotions[k]]) for k in emotions]\n",
    "            norm += np.sum(X[ii, :])\n",
    "\n",
    "        X = X / norm\n",
    "\n",
    "        return csr_matrix(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos: properly ending kills karofsky walternate identity blows joffrey kurt devil tear freya dies harvey sebastian regina morgana olivia moriarty destiny\n",
      "Neg: cory johnny tim drew often hilarious meant cody disney fed surveillance closed brian haven frequently wearing started hated bruce coincidence\n"
     ]
    }
   ],
   "source": [
    "get_metrics()\n",
    "cross_val(emotion_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [25 points] Problem 2: Motivation and Analysis \n",
    "***\n",
    "\n",
    "The job of the written portion of the homework is to convince the grader that:\n",
    "\n",
    "- Your new features work\n",
    "- You understand what the new features are doing\n",
    "- You had a clear methodology for incorporating the new features\n",
    "\n",
    "Make sure that you have examples and quantitative evidence that your features are working well. Be sure to explain how you used the data (e.g., did you have a validation set? did you do cross-validation?) and how you inspected the results. In addition, it is very important that you show some kind of an **error analysis** throughout your process.  That is, you should demonstrate that you've looked at misclassified examples and put thought into how you can craft new features to improve your model. \n",
    "\n",
    "A sure way of getting a low grade is simply listing what you tried and reporting the Kaggle score for each. You are expected to pay more attention to what is going on with the data and take a data-driven approach to feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNamed Entity Recognition\\n------------------------\\n\\nAnalysis behind choosing feature: The spoilers would contain more named entities as a spoiler would mostly be about a person or an entity in general\\n\\nQuantitative Analysis of the training set\\nMean of count of named entities per sentence for spoilers: 1.35 \\nMean of count of named entities per sentence for non-spoilers: 1.06\\n\\nIt is seen above that the average amount of named entities per sentence is more for spoilers than non-spoilers.\\n\\nExamples:\\n1. By the end of the first season, it would appear that   Warden James  is the one behind the disappearances and returns. (Spoiler) contains Warden James as the named entity.\\n2. For example, count how many times in the 1st and 2nd season we see Buster alongside   artificial hands . (Spoiler) contains Buster as the named entity.\\n3. They drink it and think they are drunk. (Non spoiler) \\n4. Including  his hand chair. (Non spoiler)\\n\\nMisclassified Example(s) (When only using count of named entity recognition as a feature)\\n\\nWhen George Michael lets Gob do an ad for his school president campaign, Gob pretty much attacks George's rival, Steve Holt, on the grounds that he doesn't even know who his father is. \\nTrue label: Non-Spoiler\\nPredicted Label: Spoiler \\n\\nThis difference occurs because the count of named entities (4) is more here detecting it as a spoiler.\\n\\nMetrics for cross validation set 1,2,3,4,5,6\\n\\n'test_tp': array([399, 392, 393, 349, 388, 457])\\n'test_fp': array([387, 388, 278, 359, 335, 273])\\n'test_fn': array([508, 522, 580, 475, 528, 691])\\n'test_tn': array([399, 392, 393, 349, 388, 457])\\n\\nAccuracy: 0.57\\n\\n\\nSentiment Recognition\\n----------------------\\n\\nSentence sentiment was analysed to see if the sentiments like anger or sadness were found more in spoilers.\\nThe confusion matrix is as follows:\\n'test_fn': array([ 297,  404,  397,  270,  433, 1113])\\n'test_fp': array([554, 520, 528, 681, 516,  18])\\n'test_tp': array([610, 510, 576, 554, 483,  35])\\n'test_tn': array([610, 510, 576, 554, 483,  35])\\n\\nIt was found that the true positives were almost equal to the false positives. Hence this feature\\ndid not add much to the classifier and was rejected.\\nAvg Accuracy over cross Validation set : 0.52\\n\\n\\nTense \\n------\\nIt is generally seen that the spoilers would rarely talk about the future hence would contain less amount of verbs with future tense. \\nWith present and past tense, it is found that spoilers contain more `past verbs` and `present verbs`.\\nFollowing is the trend observed when comparing spoilers and non-spoilers \\n\\nAverage number of verbs observed per example:\\n                Past          Present      Others (future)\\n  Spoiler     1.19083969   2.02735369   0.443775445\\n Non-Spoiler  0.99436818   1.63833157   0.73257304\\n\\n'test_tp': array([491, 521, 487, 438, 474, 468])\\n'test_fp': array([419, 463, 415, 459, 450, 273])\\n'test_fn': array([416, 393, 486, 386, 442, 680])\\n'test_tn': array([491, 521, 487, 438, 474, 468])\\n\\nAvg Accuracy over cross Validation set : 0.58\\n\\n\\nTrope\\n-----\\nTrope was found to be a good predictor for spoiler as it is the summary of each sentence in a word.\\nCharacter ngrams were used to capture words like 'kill', 'die' (strong predictors of a class) in a trope\\nand was found to increase the accuracy. \\n'test_fn': array([202, 187, 267, 172, 192, 268])\\n'test_fp': array([549, 600, 497, 650, 547, 439])\\n'test_tp': array([705, 727, 706, 652, 724, 880])\\n'test_tn': array([705, 727, 706, 652, 724, 880])\\n\\nAvg Accuracy over cross Validation set : 0.63\\n\\nMisclassified examples:\\nSentence: Just prior to the one Liebgott's BSOD, the previously chipper O'Keefe was shown to heavily affected by the concentration camp.\\nTrope: HeroicBSOD\\n\\nPredicted Label: Spoiler\\nTrue Label : Not a Spoiler\\n\\nSince maximum of the sentences with the trope HeroicBSOD (atleast in the range [517-524]) are labelled as True(are a spoiler),\\nthe sentence with this trope is labelled as a spoiler although it is not.\\n\\n\\nBag of words(unigrams and bigrams) with character ngrams\\n--------------------------------------------------------\\nThis feature was the most useful since it captures the characteristics of a spoiler through words.\\nFor example many of the spoilers would be about revealing a plot wherin a murder takes place or someone dies.\\nSo the words 'kill', 'die' are captured through this model and assigned a higher weight.\\nSimilarly for group of words (bigrams).\\n\\nCharacted ngrams (2, 9) were used along with bag of words (unigrams and bigrams)\\nfor the same reason as mentioned before.\\n\\nAverage accuracy across Cross Validation set: 0.66\\n\\nMissclassified Examples:\\n1. Another shows the two catching a burglar in their flat who they sit on, tie to chair with sellotape and try to poison.\\n2. One episode sees Eddie and Richie put in charge of running their landlord's shop when he has to go to a funeral.\\n\\nBoth the examples are not spoilers and are labelled as spoilers. This is because they contain words like\\n'funeral', 'poison', 'episode', 'burglar' which are indicators of a spoiler and would have more weight associated\\nwith them to indicate they are spoilers.\\n\\n\\nCount Strong Word Predictors Of Spoiler\\n---------------------------------------\\nThe words which were found to be strong predictors of spoilers were taken as separate features.\\nSee graph below.\\n\\n\\n\\nTaking all the Features in a pipeline\\n-------------------------------------\\n\\nOverall Test Accuracy: 0.705\\nOverall Train Accuracy: 0.79\\n\\nMisclassified Examples: \\n1.  Sentence - Donna from Season 4 turned out to have a heart ailment and had to leave the show.\\n    Trope    - DownerEnding\\n    \\n    True Label- Non Spoiler\\n    Predicted Label - Spoiler\\n    \\nThe sentence has named entities (Donna), Words such as 'Season, turn' which are strong predictors of a spoiler\\naccording to the model. Also the trope has words 'End' which is again a strong predictor of a spoiler.\\nHence the classifier confuses this example and classifies it as a spoiler.\\n\\n2.  Sentence - , sending her to the ground.\\n    Trope    - KickTheDog\\n    \\n    True Label - Spoiler\\n    Predicted Label - Non Spoiler\\n\\nThe sentence has no strong features to indicate if it is a spoiler.\\nTherefore the classifier classifies it as a Non spoiler\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    All the features below are evaluated using a cross validation set with k=6.\n",
    "    Each of the features has been analysed separately (taking only that feature into consideration while classifying)\n",
    "    In the end the combination of these features has been evaluated.\n",
    "    \n",
    "    The true positives, false positives, true negatives and false negatives values\n",
    "    are also calculated over a cross validation set k=6. The features are kept if\n",
    "    there is a acceptable precision and recall. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Named Entity Recognition\n",
    "------------------------\n",
    "\n",
    "Analysis behind choosing feature: The spoilers would contain more named entities as a spoiler would mostly be about a person or an entity in general\n",
    "\n",
    "Quantitative Analysis of the training set\n",
    "Mean of count of named entities per sentence for spoilers: 1.35 \n",
    "Mean of count of named entities per sentence for non-spoilers: 1.06\n",
    "\n",
    "It is seen above that the average amount of named entities per sentence is more for spoilers than non-spoilers.\n",
    "\n",
    "Examples:\n",
    "1. By the end of the first season, it would appear that   Warden James  is the one behind the disappearances and returns. (Spoiler) contains Warden James as the named entity.\n",
    "2. For example, count how many times in the 1st and 2nd season we see Buster alongside   artificial hands . (Spoiler) contains Buster as the named entity.\n",
    "3. They drink it and think they are drunk. (Non spoiler) \n",
    "4. Including  his hand chair. (Non spoiler)\n",
    "\n",
    "Misclassified Example(s) (When only using count of named entity recognition as a feature)\n",
    "\n",
    "When George Michael lets Gob do an ad for his school president campaign, Gob pretty much attacks George's rival, Steve Holt, on the grounds that he doesn't even know who his father is. \n",
    "True label: Non-Spoiler\n",
    "Predicted Label: Spoiler \n",
    "\n",
    "This difference occurs because the count of named entities (4) is more here detecting it as a spoiler.\n",
    "\n",
    "Metrics for cross validation set 1,2,3,4,5,6\n",
    "\n",
    "'test_tp': array([399, 392, 393, 349, 388, 457])\n",
    "'test_fp': array([387, 388, 278, 359, 335, 273])\n",
    "'test_fn': array([508, 522, 580, 475, 528, 691])\n",
    "'test_tn': array([399, 392, 393, 349, 388, 457])\n",
    "\n",
    "Accuracy: 0.57\n",
    "\n",
    "\n",
    "Sentiment Recognition\n",
    "----------------------\n",
    "\n",
    "Sentence sentiment was analysed to see if the sentiments like anger or sadness were found more in spoilers.\n",
    "The confusion matrix is as follows:\n",
    "'test_fn': array([ 297,  404,  397,  270,  433, 1113])\n",
    "'test_fp': array([554, 520, 528, 681, 516,  18])\n",
    "'test_tp': array([610, 510, 576, 554, 483,  35])\n",
    "'test_tn': array([610, 510, 576, 554, 483,  35])\n",
    "\n",
    "Feature had a very low f1 measure.Hence this feature\n",
    "did not add much to the classifier and was rejected.\n",
    "Avg Accuracy over cross Validation set : 0.52\n",
    "\n",
    "\n",
    "Tense \n",
    "------\n",
    "It is generally seen that the spoilers would rarely talk about the future hence would contain less amount of verbs with future tense. \n",
    "With present and past tense, it is found that spoilers contain more `past verbs` and `present verbs`.\n",
    "Following is the trend observed when comparing spoilers and non-spoilers \n",
    "\n",
    "Average number of verbs observed per example:\n",
    "                Past          Present      Others (future)\n",
    "  Spoiler     1.19083969   2.02735369   0.443775445\n",
    " Non-Spoiler  0.99436818   1.63833157   0.73257304\n",
    "\n",
    "'test_tp': array([491, 521, 487, 438, 474, 468])\n",
    "'test_fp': array([419, 463, 415, 459, 450, 273])\n",
    "'test_fn': array([416, 393, 486, 386, 442, 680])\n",
    "'test_tn': array([491, 521, 487, 438, 474, 468])\n",
    "\n",
    "Avg Accuracy over cross Validation set : 0.58\n",
    "\n",
    "\n",
    "Trope\n",
    "-----\n",
    "Trope was found to be a good predictor for spoiler as it is the summary of each sentence in a word.\n",
    "Character ngrams were used to capture words like 'kill', 'die' (strong predictors of a class) in a trope\n",
    "and was found to increase the accuracy. \n",
    "'test_fn': array([202, 187, 267, 172, 192, 268])\n",
    "'test_fp': array([549, 600, 497, 650, 547, 439])\n",
    "'test_tp': array([705, 727, 706, 652, 724, 880])\n",
    "'test_tn': array([705, 727, 706, 652, 724, 880])\n",
    "\n",
    "Avg Accuracy over cross Validation set : 0.63\n",
    "\n",
    "Misclassified examples:\n",
    "Sentence: Just prior to the one Liebgott's BSOD, the previously chipper O'Keefe was shown to heavily affected by the concentration camp.\n",
    "Trope: HeroicBSOD\n",
    "\n",
    "Predicted Label: Spoiler\n",
    "True Label : Not a Spoiler\n",
    "\n",
    "Since maximum of the sentences with the trope HeroicBSOD (atleast in the range [517-524]) are labelled as True(are a spoiler),\n",
    "the sentence with this trope is labelled as a spoiler although it is not.\n",
    "\n",
    "\n",
    "Bag of words(unigrams and bigrams) with character ngrams\n",
    "--------------------------------------------------------\n",
    "This feature was the most useful since it captures the characteristics of a spoiler through words.\n",
    "For example many of the spoilers would be about revealing a plot wherin a murder takes place or someone dies.\n",
    "So the words 'kill', 'die' are captured through this model and assigned a higher weight.\n",
    "Similarly for group of words (bigrams).\n",
    "\n",
    "Characted ngrams (2, 9) were used along with bag of words (unigrams and bigrams)\n",
    "for the same reason as mentioned before.\n",
    "\n",
    "Average accuracy across Cross Validation set: 0.66\n",
    "\n",
    "Missclassified Examples:\n",
    "1. Another shows the two catching a burglar in their flat who they sit on, tie to chair with sellotape and try to poison.\n",
    "2. One episode sees Eddie and Richie put in charge of running their landlord's shop when he has to go to a funeral.\n",
    "\n",
    "Both the examples are not spoilers and are labelled as spoilers. This is because they contain words like\n",
    "'funeral', 'poison', 'episode', 'burglar' which are indicators of a spoiler and would have more weight associated\n",
    "with them to indicate they are spoilers.\n",
    "\n",
    "\n",
    "Count Strong Word Predictors Of Spoiler\n",
    "---------------------------------------\n",
    "The words which were found to be strong predictors of spoilers were taken as separate features.\n",
    "See graph below.\n",
    "\n",
    "\n",
    "\n",
    "Taking all the Features in a pipeline\n",
    "-------------------------------------\n",
    "\n",
    "Overall Test Accuracy: 0.705\n",
    "Overall Train Accuracy: 0.79\n",
    "\n",
    "Misclassified Examples: \n",
    "1.  Sentence - Donna from Season 4 turned out to have a heart ailment and had to leave the show.\n",
    "    Trope    - DownerEnding\n",
    "    \n",
    "    True Label- Non Spoiler\n",
    "    Predicted Label - Spoiler\n",
    "    \n",
    "The sentence has named entities (Donna), Words such as 'Season, turn' which are strong predictors of a spoiler\n",
    "according to the model. Also the trope has words 'End' which is again a strong predictor of a spoiler.\n",
    "Hence the classifier confuses this example and classifies it as a spoiler.\n",
    "\n",
    "2.  Sentence - , sending her to the ground.\n",
    "    Trope    - KickTheDog\n",
    "    \n",
    "    True Label - Spoiler\n",
    "    Predicted Label - Non Spoiler\n",
    "\n",
    "The sentence has no strong features to indicate if it is a spoiler.\n",
    "Therefore the classifier classifies it as a Non spoiler\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints \n",
    "***\n",
    "\n",
    "- Don't use all the data until you're ready. \n",
    "\n",
    "- Examine the features that are being used.\n",
    "\n",
    "- Do error analyses.\n",
    "\n",
    "- If you have questions that aren’t answered in this list, feel free to ask them on Piazza.\n",
    "\n",
    "### FAQs \n",
    "***\n",
    "\n",
    "> Can I heavily modify the FeatEngr class? \n",
    "\n",
    "Totally.  This was just a starting point.  The only thing you cannot modify is the LogisticRegression classifier.  \n",
    "\n",
    "> Can I look at TV Tropes?\n",
    "\n",
    "In order to gain insight about the data yes, however, your feature extraction cannot use any additional data (beyond what I've given you) from the TV Tropes webpage.\n",
    "\n",
    "> Can I use IMDB, Wikipedia, or a dictionary?\n",
    "\n",
    "Yes, but you are not required to. So long as your features are fully automated, they can use any dataset other than TV Tropes. Be careful, however, that your dataset does not somehow include TV Tropes (e.g. using all webpages indexed by Google will likely include TV Tropes).\n",
    "\n",
    "> Can I combine features?\n",
    "\n",
    "Yes, and you probably should. This will likely be quite effective.\n",
    "\n",
    "> Can I use Mechanical Turk?\n",
    "\n",
    "That is not fully automatic, so no. You should be able to run your feature extraction without any human intervention. If you want to collect data from Mechanical Turk to train a classifier that you can then use to generate your features, that is fine. (But that’s way too much work for this assignment.)\n",
    "\n",
    "> Can I use a Neural Network to automatically generate derived features? \n",
    "\n",
    "No. This assignment is about your ability to extract meaningful features from the data using your own experimentation and experience.\n",
    "\n",
    "> What sort of improvement is “good” or “enough”?\n",
    "\n",
    "If you have 10-15% improvement over the baseline (on the Public Leaderboard) with your features, that’s more than sufficient. If you fail to get that improvement but have tried reasonable features, that satisfies the requirements of assignment. However, the extra credit for “winning” the class competition depends on the performance of other students.\n",
    "\n",
    "> Where do I start?  \n",
    "\n",
    "It might be a good idea to look at the in-class notebook associated with the Feature Engineering lecture where we did similar experiments. \n",
    "\n",
    "\n",
    "> Can I use late days on this assignment? \n",
    "\n",
    "You can use late days for the write-up submission, but the Kaggle competition closes at **4:59pm on Friday February 23rd**\n",
    "\n",
    "> Why does it say that the competition ends at 11:59pm when the assignment says 4:59pm? \n",
    "\n",
    "The end time/date are in UTC.  11:59pm UTC is equivalent to 4:59pm MST.  Kaggle In-Class does not allow us to change this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfUmqyBVkuSwNnU1cKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f52690524a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n Blue graph indicates count of words for sentences labelled as spoiler \\n Red graph indicates count of words for sentences labelled as non-spoiler \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['kill', 'die', 'end', 'death', 'finale', 'turn', 'reveal', 'murder']\n",
    "non_spoiler_word_counts = np.array([ 159, 128, 509, 58, 20, 166, 53, 51])\n",
    "spoiler_word_counts = np.array([ 580, 295, 899, 215, 101, 376, 219, 149])\n",
    "\n",
    "x = np.arange(8)\n",
    "plt.plot(x, spoiler_word_counts.T, x, non_spoiler_word_counts.T)\n",
    "plt.title(\"Plot for word counts for spoiler and non-spoiler sentences\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    " Blue graph indicates count of words for sentences labelled as spoiler \n",
    " Red graph indicates count of words for sentences labelled as non-spoiler \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
